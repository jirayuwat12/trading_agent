{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trading_agent.trading_simulator import TradingSimulator, TradingSimulatorConfig\n",
    "from trading_agent.random_trading_agent import RandomTradingAgent\n",
    "from trading_agent.explainable_option_trading_agent import ExplainableOptionTradingAgent\n",
    "from trading_agent.base_trading_agent import BaseTradingAgent\n",
    "from trading_agent.utils.order_hist_visualizer import plot_order_history\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb586c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.2\n",
    "\n",
    "REWARD_FACTOR = 0.99\n",
    "LOSS_FACTOR = 1.00\n",
    "INIT_BALANCE = 100\n",
    "\n",
    "RANDOM_TESTING_TIMES = 3000\n",
    "EXPLAINABLE_TESTING_TIMES = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e723f",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a23285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_csv(\"../data/tesla_tweets_with_sentiment_all.csv\")\n",
    "sentiment_df[\"Date\"] = pd.to_datetime(sentiment_df[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4634d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute split date\n",
    "dates = sentiment_df[\"Date\"].unique()[::-1]\n",
    "split_index = int(len(dates) * (1 - TEST_RATIO))\n",
    "split_date = dates[split_index]\n",
    "print(f\"Split date: {split_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load price data\n",
    "price_df = pd.read_csv(\"../data/date_with_x_t.csv\")\n",
    "price_df = price_df.dropna()\n",
    "price_df[\"Date\"] = pd.to_datetime(price_df[\"Date\"]).dt.date\n",
    "price_df[\"is_train\"] = price_df[\"Date\"] < split_date\n",
    "\n",
    "# Merge price and sentiment dataframes and mark train/test split\n",
    "price_and_sentiment_df = pd.merge(price_df, sentiment_df, on=\"Date\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb538e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_and_sentiment_df.groupby(\"Date\").agg(\n",
    "    postive_count=(\"sentiment_label\", lambda x: (x == \"positive\").sum()),\n",
    "    negative_count=(\"sentiment_label\", lambda x: (x == \"negative\").sum()),\n",
    "    neutral_count=(\"sentiment_label\", lambda x: (x == \"neutral\").sum()),\n",
    ").mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac41917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalibrate_sentiment(price_and_sentiment_df, max_date):\n",
    "    \"\"\"\n",
    "    Due to very few negative tweets, we need to recalibrate the sentiment scores\n",
    "    Which this function will label low confidence 'positive' sentiments as 'neutral'\n",
    "    and the threshold for 'positive' sentiment is set by use the minimum score that make mean of\n",
    "    negative sentiment and positive sentiment are most close\n",
    "    \"\"\"\n",
    "    # Compute the sum of positive and negative sentiment counts each day\n",
    "    price_and_sentiment_df = price_and_sentiment_df.groupby(\"Date\").agg(\n",
    "        postive_count=(\"sentiment_label\", lambda x: (x == \"positive\").sum()),\n",
    "        negative_count=(\"sentiment_label\", lambda x: (x == \"negative\").sum()),\n",
    "        neutral_count=(\"sentiment_label\", lambda x: (x == \"neutral\").sum()),\n",
    "        x_t=(\"x_t\", \"first\"),\n",
    "        is_train=(\"is_train\", \"first\"),\n",
    "    )\n",
    "    # get the mean of x_t over 5 days\n",
    "    CONSECUTIVE_DAYS = 3\n",
    "    price_and_sentiment_df[\"x_t_mean\"] = price_and_sentiment_df[\"x_t\"].rolling(CONSECUTIVE_DAYS).mean()\n",
    "    price_and_sentiment_df[\"pos_count_first\"] = price_and_sentiment_df[\"postive_count\"].shift(CONSECUTIVE_DAYS)\n",
    "    price_and_sentiment_df[\"neg_count_first\"] = price_and_sentiment_df[\"negative_count\"].shift(CONSECUTIVE_DAYS)\n",
    "    price_and_sentiment_df[\"neutral_count_first\"] = price_and_sentiment_df[\"neutral_count\"].shift(CONSECUTIVE_DAYS)\n",
    "\n",
    "    # Get the positive count that makes the price up for CONSECUTIVE_DAYS\n",
    "    mean_target_pos = price_and_sentiment_df[price_and_sentiment_df[\"x_t_mean\"] == 1][\"pos_count_first\"].mean()\n",
    "    mean_target_neg = price_and_sentiment_df[price_and_sentiment_df[\"x_t_mean\"] == 0][\"neg_count_first\"].mean()\n",
    "    weight_for_neg = 1 / (mean_target_neg / mean_target_pos)\n",
    "    print(f\"Weight for negative sentiment: {weight_for_neg}\")\n",
    "    sentiment_weights = {\"positive\": 1, \"negative\": float(weight_for_neg), \"neutral\": 1}\n",
    "\n",
    "    price_and_sentiment_df[\"positive_weight\"] = price_and_sentiment_df[\"postive_count\"] * sentiment_weights[\"positive\"]\n",
    "    price_and_sentiment_df[\"negative_weight\"] = price_and_sentiment_df[\"negative_count\"] * sentiment_weights[\"negative\"]\n",
    "    price_and_sentiment_df[\"neutral_weight\"] = price_and_sentiment_df[\"neutral_count\"] * sentiment_weights[\"neutral\"]\n",
    "\n",
    "    price_and_sentiment_df[\"sentiment_major\"] = price_and_sentiment_df[\n",
    "        [\"positive_weight\", \"negative_weight\", \"neutral_weight\"]\n",
    "    ].idxmax(axis=1)\n",
    "    price_and_sentiment_df[\"sentiment_major\"] = price_and_sentiment_df[\"sentiment_major\"].apply(\n",
    "        lambda x: x.split(\"_\")[0]\n",
    "    )\n",
    "\n",
    "    return price_and_sentiment_df, sentiment_weights\n",
    "\n",
    "\n",
    "price_and_sentiment_df, sentiment_weights = recalibrate_sentiment(price_and_sentiment_df, max_date=split_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiment_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71467cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_et = dict()\n",
    "\n",
    "sentiment_count = price_and_sentiment_df.groupby(\"sentiment_major\").agg(\n",
    "    count=(\"sentiment_major\", \"size\"),\n",
    ")\n",
    "total_count = sentiment_count[\"count\"].sum()\n",
    "\n",
    "for sentiment in sentiment_count.index:\n",
    "    p_et[sentiment] = float(sentiment_count.loc[sentiment].iloc[0] / total_count)\n",
    "\n",
    "with open(\"./p_et.json\", \"w\") as f:\n",
    "    json.dump(p_et, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07548366",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xt = dict()\n",
    "\n",
    "price_up_amount = price_and_sentiment_df[price_and_sentiment_df[\"is_train\"]][\"x_t\"].sum()\n",
    "price_down_amount = len(price_and_sentiment_df[price_and_sentiment_df[\"is_train\"]]) - price_up_amount\n",
    "total_amount = len(price_and_sentiment_df[price_and_sentiment_df[\"is_train\"]])\n",
    "\n",
    "p_xt[\"up\"] = float(price_up_amount / total_amount)\n",
    "p_xt[\"down\"] = float(price_down_amount / total_amount)\n",
    "\n",
    "with open(\"./p_xt.json\", \"w\") as f:\n",
    "    json.dump(p_xt, f, indent=4)\n",
    "pprint(p_xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_et_given_xt = defaultdict(dict)\n",
    "\n",
    "for sentiment in p_et.keys():\n",
    "    for price_state in p_xt.keys():\n",
    "        # Find prob of sentiment given price state\n",
    "        current_xt_and_et = price_and_sentiment_df[\n",
    "            (price_and_sentiment_df[\"is_train\"])\n",
    "            & (price_and_sentiment_df[\"sentiment_major\"] == sentiment)\n",
    "            & (price_and_sentiment_df[\"x_t\"] == (1 if price_state == \"up\" else 0))\n",
    "        ]\n",
    "        total_amount = len(price_and_sentiment_df[price_and_sentiment_df[\"is_train\"]])\n",
    "\n",
    "        p_et_and_xt = len(current_xt_and_et) / total_amount\n",
    "        p_et_given_xt[sentiment][price_state] = float(p_et_and_xt / p_xt[price_state])\n",
    "p_et_given_xt = dict(p_et_given_xt)\n",
    "\n",
    "with open(\"./p_et_given_xt.json\", \"w\") as f:\n",
    "    json.dump(p_et_given_xt, f, indent=4)\n",
    "pprint(p_et_given_xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xt_given_xprevt = defaultdict(dict)\n",
    "\n",
    "# Find prob of price state given previous price state\n",
    "temp_df = price_and_sentiment_df.copy()\n",
    "temp_df[\"x_t-1\"] = temp_df[\"x_t\"].shift(1).astype(\"Int64\")\n",
    "temp_df = temp_df[1:]\n",
    "\n",
    "\n",
    "for price_state in p_xt.keys():\n",
    "    for prev_price_state in p_xt.keys():\n",
    "        # Find prob of price state given previous price state\n",
    "        current_xt_and_xprevt = temp_df[\n",
    "            (temp_df[\"is_train\"])\n",
    "            & (temp_df[\"x_t\"] == (1 if price_state == \"up\" else 0))\n",
    "            & (temp_df[\"x_t-1\"] == (1 if prev_price_state == \"up\" else 0))\n",
    "        ]\n",
    "        total_amount = len(temp_df[temp_df[\"is_train\"]])\n",
    "\n",
    "        p_xt_and_xprevt = len(current_xt_and_xprevt) / total_amount\n",
    "        p_xt_given_xprevt[price_state][prev_price_state] = float(p_xt_and_xprevt / p_xt[prev_price_state])\n",
    "\n",
    "p_xt_given_xprevt = dict(p_xt_given_xprevt)\n",
    "with open(\"./p_xt_given_xprevt.json\", \"w\") as f:\n",
    "    json.dump(p_xt_given_xprevt, f, indent=4)\n",
    "\n",
    "pprint(p_xt_given_xprevt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the merged data\n",
    "price_tsla_1d = pd.read_csv(\"../data/price_1d_tsla.csv\")\n",
    "price_tsla_1d[\"Date\"] = pd.to_datetime(price_tsla_1d[\"Date\"]).dt.date\n",
    "\n",
    "df = pd.merge(price_tsla_1d, price_and_sentiment_df, on=\"Date\", how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9796311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./tesing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39adc848",
   "metadata": {},
   "source": [
    "# Run testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = \"2022-07-19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68555321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiple_times(\n",
    "    trading_agent: BaseTradingAgent, trading_sim: TradingSimulator, num_times: int = 10, tqdm_disable: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Test the trading agent multiple times and return the average profit\n",
    "    \"\"\"\n",
    "    best_result, best_state_history = None, None\n",
    "    worse_result, worse_state_history = None, None\n",
    "    run_history = []\n",
    "\n",
    "    # Run the simulation multiple times\n",
    "    for _ in tqdm(range(num_times), disable=tqdm_disable):\n",
    "        trading_agent.reset_state()\n",
    "        result = trading_sim.run_simulation(trading_agent)\n",
    "        # Store the balance history\n",
    "        run_history.append(result)\n",
    "\n",
    "        if best_result is None or result.balance > best_result.balance:\n",
    "            best_result = result\n",
    "            try:\n",
    "                best_state_history = trading_agent.state_history\n",
    "            except AttributeError:\n",
    "                best_state_history = None\n",
    "        if worse_result is None or result.balance < worse_result.balance:\n",
    "            worse_result = result\n",
    "            try:\n",
    "                worse_state_history = trading_agent.state_history\n",
    "            except AttributeError:\n",
    "                worse_state_history = None\n",
    "\n",
    "    balance_history = np.array([result.balance for result in run_history])\n",
    "\n",
    "    return {\n",
    "        \"best_result\": best_result,\n",
    "        \"worse_result\": worse_result,\n",
    "        \"best_profit\": round((best_result.balance - INIT_BALANCE) / INIT_BALANCE * 100, 2),\n",
    "        \"worse_profit\": round((worse_result.balance - INIT_BALANCE) / INIT_BALANCE * 100, 2),\n",
    "        \"average_profit\": round((balance_history.sum() / len(balance_history) - INIT_BALANCE) / INIT_BALANCE * 100, 2),\n",
    "        \"std_dev\": round((balance_history.std()), 2),\n",
    "        \"best_state_history\": best_state_history,\n",
    "        \"worse_state_history\": worse_state_history,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_sim_config = TradingSimulatorConfig(\n",
    "    price_dataframe_path=\"./tesing.csv\",\n",
    "    buy_at=\"Open\",\n",
    "    sell_at=\"Close\",\n",
    "    trade_type=\"option\",\n",
    "    reward_factor=REWARD_FACTOR,\n",
    "    loss_factor=LOSS_FACTOR,\n",
    "    initial_balance=INIT_BALANCE,\n",
    ")\n",
    "trading_sim = TradingSimulator(trading_sim_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ef210",
   "metadata": {},
   "source": [
    "## Random trading agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result, worse_result, best_profit, worse_profit, average_profit, std_dev, best_state_history, worse_state_history = test_multiple_times(\n",
    "    RandomTradingAgent(), trading_sim, num_times=RANDOM_TESTING_TIMES\n",
    ").values()\n",
    "\n",
    "print(\"Best result profit    :\", best_profit, \"%\")\n",
    "print(\"Worse result profit   :\", worse_profit, \"%\")\n",
    "print()\n",
    "print(\"Average profit        :\", average_profit, \"%\")\n",
    "print(\"Standard deviation    :\", std_dev, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be495e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_order_history(\n",
    "    best_result.order_history,\n",
    "    initial_balance=INIT_BALANCE,\n",
    "    title=\"Best result order history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d381b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_order_history(\n",
    "    orders=worse_result.order_history,\n",
    "    initial_balance=INIT_BALANCE,\n",
    "    title=\"Best result order history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f7e63",
   "metadata": {},
   "source": [
    "## Explainable trading agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trading_agent.explainable_option_trading_agent import ExplainableOptionTradingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97381ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainable_trading_agent = ExplainableOptionTradingAgent(\n",
    "    p_et_path=\"./p_et.json\",\n",
    "    p_xt_path=\"./p_xt.json\",\n",
    "    p_et_given_xt_path=\"./p_et_given_xt.json\",\n",
    "    p_xt_given_xprevt_path=\"./p_xt_given_xprevt.json\",\n",
    "    inference_method=\"forward_predict\",\n",
    "    picking_action_method=\"select_max_prob\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4157730",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result, worse_result, best_profit, worse_profit, average_profit, std_dev, best_state_history, worse_state_history = test_multiple_times(\n",
    "    explainable_trading_agent, trading_sim, num_times=EXPLAINABLE_TESTING_TIMES\n",
    ").values()\n",
    "\n",
    "print(\"Best result profit    :\", best_profit, \"%\")\n",
    "print(\"Worse result profit   :\", worse_profit, \"%\")\n",
    "print()\n",
    "print(\"Average profit        :\", average_profit, \"%\")\n",
    "print(\"Standard deviation    :\", std_dev, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c98b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_order_history(\n",
    "    best_result.order_history,\n",
    "    initial_balance=INIT_BALANCE,\n",
    "    title=\"Best result order history\",\n",
    "    test_split_date=split_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e182047",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state_history\n",
    "# Convert date and predicted_xt of each State to a dataframe\n",
    "state_history_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            # \"Date\": state.date,\n",
    "            \"Date\": pd.to_datetime(state.date).date(),\n",
    "            \"predicted_xt\": state.predicted_xt,\n",
    "        }\n",
    "        for state in best_state_history\n",
    "    ]\n",
    ")\n",
    "temp_df = pd.merge(state_history_df, price_and_sentiment_df, on=\"Date\", how=\"inner\")[[\"Date\", \"predicted_xt\", \"x_t\"]]\n",
    "temp_df[\"predicted_xt\"] = temp_df[\"predicted_xt\"].apply(lambda x: 1 if x == \"up\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebef1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(classification_report(temp_df[\"x_t\"], temp_df[\"predicted_xt\"], labels=[0, 1], target_names=[\"Down\", \"Up\"]))\n",
    "\n",
    "report = confusion_matrix(temp_df[\"x_t\"], temp_df[\"predicted_xt\"])\n",
    "sns.heatmap(\n",
    "    report,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Down\", \"Up\"],\n",
    "    yticklabels=[\"Down\", \"Up\"],\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Ground truth\")\n",
    "plt.title(\"Confusion Matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
